<html>
    <head>
        <style>
            #wizzy { width:300px; float:left; margin-right:10px}
            #chat { width:700px; float:right; margin-left:10px}
            #robotics {
                grid-area: sec1;
                font-family:sans-serif;
                color: white;
                background-color: #921613;
            }
            #conversation {
                grid-area: sec2;
                font-family:sans-serif;
                color: white;
                background-color: #171A40;
            }
            main {
                display: grid;
                grid: 'sec1' 'sec2';
            }
            ul { overflow: hidden; }
            .margin { margin-left:10px; }
            .hidden { 
                visibility: hidden;
                display:none;
            }
        </style>
    </head>
    <body>
        <main>
            <section id="robotics">
                <img id="wizzy" src="images/wizzy.jpg">
                <h1 class="margin">Assistive Robotics</h1>
                <h4 class="margin">Shared control between users and smart wheelchairs</h4>
                <p class="margin">
                    The Wizzybug is a powered wheelchair for children made by Bath based charity, Designability.
                    We are investigating how use of powered wheelchairs can be extended to include children with motor difficulties that don't allow them to accurately steer the Wizzybug.
                    If we can gain enough information about the child's goal through a noisy control signal input via the joystick, then the computer can augment the control signal to support the child in achieving their goal.
                    We don't want to make the child a passenger in their own wheelchair. 
                    The aim is to avoid the computer taking over, through the idea of <em>shared control</em>.
                </p>
                <p class="margin">
                    Our work is inspired by a branch of cybernetics called <em>Perceptual Control Theory</em>.
                </p>
                <ul>
                    <li>Robopsychology: Perceptual Control Theory and Braitenberg's vehicles (<a href="https://www.youtube.com/watch?v=qiwSli7eiS4&t=3069s">video</a>)</li>
                    <li>Robots with Purpose (<a href="https://scholar.google.co.uk/citations?view_op=view_citation&hl=en&user=k3bLaFAAAAAJ&cstart=20&pagesize=80&citation_for_view=k3bLaFAAAAAJ:RGFaLdJalmkC">article</a>)</li>
                </ul>
            </section>
            <p>
            <section id="conversation">
                <img id="chat" src="images/chat.png">
                <h1 class="margin">Conversational Interfaces</h1>
                <h4 class="margin">Goal-driven chatbots and task-oriented dialogues</h4>
                <p class="margin">
                    The example dialogue to the right is a conversational interface designed to answer questions about ongoing regeneration projects in Keynsham, 
                    research done in conjunction with Keynsham Town Council. This simple Task Oriented Dialogue uses questions from the High-Street Action Zone Project where we are creating an FAQ chatbot designed to provide complex information that is hard to organise on a conventional website.
                    It is designed to identify the user <em>intent</em> and consult a knowledge base for suitable facts that it uses in its answers.
                </p>
                <p class="margin">Seen through cybernetic specs, the goal of the chatbot is to move the conversation towards a satisfactory conclusion.
                </p>
                <ul>
                    <li>ChatBot integration with Knowledge Graph technology (<a href="FETEnterpriseProjects2020-2021.pdf">FET Enterprise Projects 2020-2021</a>)</li>
                    <li>Inter-annotator Agreement Using the Conversation Analysis Modelling Schema, for Dialogue (<a href="https://www.researchgate.net/publication/357895917_Inter-annotator_Agreement_Using_the_Conversation_Analysis_Modelling_Schema_for_Dialogue">article</a>)</li>
                    <li>Conversation Analysis Structured Dialogue for Multi-Domain Dialogue Management (<a href="https://www.researchgate.net/publication/329809503_Conversation_Analysis_Structured_Dialogue_for_Multi-Domain_Dialogue_Management">paper</a>)</li>
                    <li>Sentence encoding for Dialogue Act classification (<a href="https://www.researchgate.net/publication/355858479_Sentence_encoding_for_Dialogue_Act_classification">article</a>>)</li>
                    <li>Task-oriented Dialogue Systems: performance vs. quality-optima, a review (<a href="https://www.researchgate.net/publication/357239121_Task-oriented_Dialogue_Systems_performance_vs_quality-optima_a_review">preprint</a>)</li>
                    <li>Understanding Learning Strategy as Conversation (<a href="https://www.researchgate.net/publication/324898015_Understanding_Learning_Strategy_as_Conversation">paper</a>)</li>
                </ul>
            </section>
        </main>
        <script>
            hash = window.location.hash;
            if (hash) {
                hash = hash.substring(1);
                sections = document.getElementsByTagName('section');
                for (i=0; i<sections.length; i++) {
                    if (sections[i].id!=hash) {
                        sections[i].classList.add("hidden");
                    }
                }
            }
        </script>
    </body>
</html>